{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.0.0\n",
      "sys.version_info(major=3, minor=7, micro=7, releaselevel='final', serial=0)\n",
      "matplotlib 3.2.2\n",
      "numpy 1.18.5\n",
      "pandas 1.0.5\n",
      "sklearn 0.21.2\n",
      "tensorflow 2.0.0\n",
      "tensorflow_core.keras 2.2.4-tf\n"
     ]
    }
   ],
   "source": [
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import sklearn\n",
    "import pandas as pd\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow import keras\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3' \n",
    "print(tf.__version__)\n",
    "print(sys.version_info)\n",
    "\n",
    "for module in mpl,np,pd,sklearn,tf,keras:\n",
    "    print(module.__name__,module.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>survived</th>\n",
       "      <th>sex</th>\n",
       "      <th>age</th>\n",
       "      <th>n_siblings_spouses</th>\n",
       "      <th>parch</th>\n",
       "      <th>fare</th>\n",
       "      <th>class</th>\n",
       "      <th>deck</th>\n",
       "      <th>embark_town</th>\n",
       "      <th>alone</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>Third</td>\n",
       "      <td>unknown</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>First</td>\n",
       "      <td>C</td>\n",
       "      <td>Cherbourg</td>\n",
       "      <td>n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>Third</td>\n",
       "      <td>unknown</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>First</td>\n",
       "      <td>C</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>male</td>\n",
       "      <td>28.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.4583</td>\n",
       "      <td>Third</td>\n",
       "      <td>unknown</td>\n",
       "      <td>Queenstown</td>\n",
       "      <td>y</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   survived     sex   age  n_siblings_spouses  parch     fare  class     deck  \\\n",
       "0         0    male  22.0                   1      0   7.2500  Third  unknown   \n",
       "1         1  female  38.0                   1      0  71.2833  First        C   \n",
       "2         1  female  26.0                   0      0   7.9250  Third  unknown   \n",
       "3         1  female  35.0                   1      0  53.1000  First        C   \n",
       "4         0    male  28.0                   0      0   8.4583  Third  unknown   \n",
       "\n",
       "   embark_town alone  \n",
       "0  Southampton     n  \n",
       "1    Cherbourg     n  \n",
       "2  Southampton     y  \n",
       "3  Southampton     n  \n",
       "4   Queenstown     y  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_file = \"./data/titanic/train.csv\"\n",
    "eval_file = \"./data/titanic/eval.csv\"\n",
    "\n",
    "train_df = pd.read_csv(train_file)\n",
    "eval_df = pd.read_csv(eval_file)\n",
    "\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = train_df.pop(\"survived\")\n",
    "y_eval = eval_df.pop(\"survived\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sex ['male' 'female']\n",
      "n_siblings_spouses [1 0 3 4 2 5 8]\n",
      "parch [0 1 2 5 3 4]\n",
      "class ['Third' 'First' 'Second']\n",
      "deck ['unknown' 'C' 'G' 'A' 'B' 'D' 'F' 'E']\n",
      "embark_town ['Southampton' 'Cherbourg' 'Queenstown' 'unknown']\n",
      "alone ['n' 'y']\n"
     ]
    }
   ],
   "source": [
    "categorical_columns = ['sex', 'n_siblings_spouses', 'parch', 'class',\n",
    "                       'deck', 'embark_town', 'alone']\n",
    "numeric_columns = ['age', 'fare']\n",
    "\n",
    "feature_columns = []\n",
    "for categorical_column in categorical_columns:\n",
    "    vocab = train_df[categorical_column].unique()\n",
    "    print(categorical_column, vocab)\n",
    "    feature_columns.append(\n",
    "        tf.feature_column.indicator_column(\n",
    "            tf.feature_column.categorical_column_with_vocabulary_list(\n",
    "                categorical_column, vocab)))\n",
    "\n",
    "for categorical_column in numeric_columns:\n",
    "    feature_columns.append(\n",
    "        tf.feature_column.numeric_column(\n",
    "            categorical_column, dtype=tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 离散型特征\n",
    "# categorical_columns = [\"sex\",\"n_siblings_spouses\",\"parch\",\"class\",\"deck\",\"embark_town\",\"alone\"]\n",
    "# # 连续型特征\n",
    "# numeric_columns = [\"age\",\"fare\"]\n",
    "\n",
    "# feature_columns = []\n",
    "\n",
    "# # 对离散型特征数据的处理\n",
    "# for categorical_column in categorical_columns:\n",
    "#     # 获得所有可能的值   \n",
    "#     vocab = train_df[categorical_column].unique()\n",
    "#     print(categorical_column,vocab)\n",
    "#     # indicator_column:对离散型数据进行onehot编码\n",
    "#     feature_columns.append(tf.feature_column.indicator_column(tf.feature_column.categorical_column_with_vocabulary_list(\n",
    "#         categorical_column,vocab\n",
    "#     )))\n",
    "    \n",
    "# # 对连续型特征数据进行处理\n",
    "# for categorical_column in numeric_columns:\n",
    "#     feature_columns.append(tf.feature_column.numeric_column(categorical_column,dtype=tf.float32))\n",
    "\n",
    "\n",
    "# print(feature_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_dataset(data_df, label_df, epochs = 10, shuffle = True,\n",
    "                 batch_size = 32):\n",
    "    dataset = tf.data.Dataset.from_tensor_slices(\n",
    "        (dict(data_df), label_df))\n",
    "    if shuffle:\n",
    "        dataset = dataset.shuffle(10000)\n",
    "    dataset = dataset.repeat(epochs).batch(batch_size)\n",
    "    return dataset\n",
    "\n",
    "# train_dataset = make_dataset(train_df,y_train,batch_size=5)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      0\n",
       "1      1\n",
       "2      1\n",
       "3      1\n",
       "4      0\n",
       "      ..\n",
       "622    0\n",
       "623    0\n",
       "624    1\n",
       "625    0\n",
       "626    0\n",
       "Name: survived, Length: 627, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using default config.\n",
      "INFO:tensorflow:Using config: {'_model_dir': 'baseline_model', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true\n",
      "graph_options {\n",
      "  rewrite_options {\n",
      "    meta_optimizer_iterations: ONE\n",
      "  }\n",
      "}\n",
      ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x000001498907DCC8>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "output_dir = 'baseline_model'\n",
    "if not os.path.exists(output_dir):\n",
    "    os.mkdir(output_dir)\n",
    "\n",
    "baseline_estimator = tf.compat.v1.estimator.BaselineClassifier(\n",
    "    model_dir = output_dir,\n",
    "    n_classes = 2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From F:\\Anaconda3\\envs\\tf2\\lib\\site-packages\\tensorflow_core\\python\\ops\\resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n",
      "WARNING:tensorflow:From F:\\Anaconda3\\envs\\tf2\\lib\\site-packages\\tensorflow_core\\python\\training\\training_util.py:236: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "WARNING:tensorflow:From F:\\Anaconda3\\envs\\tf2\\lib\\site-packages\\tensorflow_estimator\\python\\estimator\\canned\\head.py:437: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.cast` instead.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Saving checkpoints for 0 into baseline_model\\model.ckpt.\n",
      "INFO:tensorflow:loss = 22.18071, step = 0\n",
      "INFO:tensorflow:global_step/sec: 356.686\n",
      "INFO:tensorflow:loss = 19.829483, step = 100 (0.268 sec)\n",
      "INFO:tensorflow:global_step/sec: 501.302\n",
      "INFO:tensorflow:loss = 19.92646, step = 200 (0.198 sec)\n",
      "INFO:tensorflow:global_step/sec: 542.025\n",
      "INFO:tensorflow:loss = 22.572939, step = 300 (0.186 sec)\n",
      "INFO:tensorflow:global_step/sec: 533.338\n",
      "INFO:tensorflow:loss = 22.591326, step = 400 (0.187 sec)\n",
      "INFO:tensorflow:global_step/sec: 524.961\n",
      "INFO:tensorflow:loss = 20.705647, step = 500 (0.189 sec)\n",
      "INFO:tensorflow:global_step/sec: 524.958\n",
      "INFO:tensorflow:loss = 21.653004, step = 600 (0.190 sec)\n",
      "INFO:tensorflow:global_step/sec: 566.485\n",
      "INFO:tensorflow:loss = 24.485996, step = 700 (0.178 sec)\n",
      "INFO:tensorflow:global_step/sec: 569.7\n",
      "INFO:tensorflow:loss = 20.725449, step = 800 (0.176 sec)\n",
      "INFO:tensorflow:global_step/sec: 544.931\n",
      "INFO:tensorflow:loss = 22.10201, step = 900 (0.183 sec)\n",
      "INFO:tensorflow:global_step/sec: 516.842\n",
      "INFO:tensorflow:loss = 22.090303, step = 1000 (0.194 sec)\n",
      "INFO:tensorflow:global_step/sec: 566.48\n",
      "INFO:tensorflow:loss = 22.979649, step = 1100 (0.177 sec)\n",
      "INFO:tensorflow:global_step/sec: 569.7\n",
      "INFO:tensorflow:loss = 21.179117, step = 1200 (0.175 sec)\n",
      "INFO:tensorflow:global_step/sec: 541.988\n",
      "INFO:tensorflow:loss = 22.078684, step = 1300 (0.185 sec)\n",
      "INFO:tensorflow:global_step/sec: 511.568\n",
      "INFO:tensorflow:loss = 21.640871, step = 1400 (0.196 sec)\n",
      "INFO:tensorflow:global_step/sec: 498.844\n",
      "INFO:tensorflow:loss = 21.650627, step = 1500 (0.200 sec)\n",
      "INFO:tensorflow:global_step/sec: 475.197\n",
      "INFO:tensorflow:loss = 21.179783, step = 1600 (0.210 sec)\n",
      "INFO:tensorflow:global_step/sec: 514.194\n",
      "INFO:tensorflow:loss = 20.264526, step = 1700 (0.194 sec)\n",
      "INFO:tensorflow:global_step/sec: 579.581\n",
      "INFO:tensorflow:loss = 19.88564, step = 1800 (0.173 sec)\n",
      "INFO:tensorflow:global_step/sec: 557.04\n",
      "INFO:tensorflow:loss = 22.558662, step = 1900 (0.180 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 1960 into baseline_model\\model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 7.7185345.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow_estimator.python.estimator.canned.baseline.BaselineClassifier at 0x14989094c88>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "baseline_estimator.train(input_fn = lambda : make_dataset(\n",
    "    train_df, y_train, epochs = 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n",
      "WARNING:tensorflow:From F:\\Anaconda3\\envs\\tf2\\lib\\site-packages\\tensorflow_core\\python\\ops\\metrics_impl.py:2026: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Deprecated in favor of operator or tf.math.divide.\n",
      "WARNING:tensorflow:Trapezoidal rule is known to produce incorrect PR-AUCs; please switch to \"careful_interpolation\" instead.\n",
      "WARNING:tensorflow:Trapezoidal rule is known to produce incorrect PR-AUCs; please switch to \"careful_interpolation\" instead.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2020-07-15T16:33:51Z\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from baseline_model\\model.ckpt-1960\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Finished evaluation at 2020-07-15-16:33:52\n",
      "INFO:tensorflow:Saving dict for global step 1960: accuracy = 0.625, accuracy_baseline = 0.625, auc = 0.5, auc_precision_recall = 0.6875, average_loss = 0.6619658, global_step = 1960, label/mean = 0.375, loss = 12.482783, precision = 0.0, prediction/mean = 0.3888027, recall = 0.0\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 1960: baseline_model\\model.ckpt-1960\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'accuracy': 0.625,\n",
       " 'accuracy_baseline': 0.625,\n",
       " 'auc': 0.5,\n",
       " 'auc_precision_recall': 0.6875,\n",
       " 'average_loss': 0.6619658,\n",
       " 'label/mean': 0.375,\n",
       " 'loss': 12.482783,\n",
       " 'precision': 0.0,\n",
       " 'prediction/mean': 0.3888027,\n",
       " 'recall': 0.0,\n",
       " 'global_step': 1960}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "baseline_estimator.evaluate(input_fn= lambda :make_dataset(eval_df,y_eval,epochs=1,shuffle=False,batch_size=20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using default config.\n",
      "INFO:tensorflow:Using config: {'_model_dir': 'linear_model', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true\n",
      "graph_options {\n",
      "  rewrite_options {\n",
      "    meta_optimizer_iterations: ONE\n",
      "  }\n",
      "}\n",
      ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x0000014A07762188>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "WARNING:tensorflow:Layer linear/linear_model is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:From F:\\Anaconda3\\envs\\tf2\\lib\\site-packages\\tensorflow_core\\python\\feature_column\\feature_column_v2.py:518: Layer.add_variable (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `layer.add_weight` method instead.\n",
      "WARNING:tensorflow:From F:\\Anaconda3\\envs\\tf2\\lib\\site-packages\\tensorflow_core\\python\\feature_column\\feature_column_v2.py:4276: IndicatorColumn._variable_shape (from tensorflow.python.feature_column.feature_column_v2) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "The old _FeatureColumn APIs are being deprecated. Please use the new FeatureColumn APIs instead.\n",
      "WARNING:tensorflow:From F:\\Anaconda3\\envs\\tf2\\lib\\site-packages\\tensorflow_core\\python\\feature_column\\feature_column_v2.py:4331: VocabularyListCategoricalColumn._num_buckets (from tensorflow.python.feature_column.feature_column_v2) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "The old _FeatureColumn APIs are being deprecated. Please use the new FeatureColumn APIs instead.\n",
      "WARNING:tensorflow:From F:\\Anaconda3\\envs\\tf2\\lib\\site-packages\\tensorflow_core\\python\\keras\\optimizer_v2\\ftrl.py:143: calling Constant.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Saving checkpoints for 0 into linear_model\\model.ckpt.\n",
      "INFO:tensorflow:loss = 0.6931472, step = 0\n",
      "INFO:tensorflow:global_step/sec: 181.973\n",
      "INFO:tensorflow:loss = 0.372478, step = 100 (0.551 sec)\n",
      "INFO:tensorflow:global_step/sec: 250.044\n",
      "INFO:tensorflow:loss = 0.5268638, step = 200 (0.400 sec)\n",
      "INFO:tensorflow:global_step/sec: 253.841\n",
      "INFO:tensorflow:loss = 0.54549146, step = 300 (0.393 sec)\n",
      "INFO:tensorflow:global_step/sec: 243.953\n",
      "INFO:tensorflow:loss = 0.45490128, step = 400 (0.411 sec)\n",
      "INFO:tensorflow:global_step/sec: 249.428\n",
      "INFO:tensorflow:loss = 0.39593178, step = 500 (0.401 sec)\n",
      "INFO:tensorflow:global_step/sec: 250.668\n",
      "INFO:tensorflow:loss = 0.45040676, step = 600 (0.399 sec)\n",
      "INFO:tensorflow:global_step/sec: 241.608\n",
      "INFO:tensorflow:loss = 0.46033016, step = 700 (0.414 sec)\n",
      "INFO:tensorflow:global_step/sec: 243.367\n",
      "INFO:tensorflow:loss = 0.39049733, step = 800 (0.410 sec)\n",
      "INFO:tensorflow:global_step/sec: 258.42\n",
      "INFO:tensorflow:loss = 0.3586672, step = 900 (0.388 sec)\n",
      "INFO:tensorflow:global_step/sec: 255.134\n",
      "INFO:tensorflow:loss = 0.54490244, step = 1000 (0.392 sec)\n",
      "INFO:tensorflow:global_step/sec: 252.563\n",
      "INFO:tensorflow:loss = 0.5033057, step = 1100 (0.395 sec)\n",
      "INFO:tensorflow:global_step/sec: 253.841\n",
      "INFO:tensorflow:loss = 0.31383428, step = 1200 (0.395 sec)\n",
      "INFO:tensorflow:global_step/sec: 246.964\n",
      "INFO:tensorflow:loss = 0.41747007, step = 1300 (0.405 sec)\n",
      "INFO:tensorflow:global_step/sec: 244.555\n",
      "INFO:tensorflow:loss = 0.39339685, step = 1400 (0.409 sec)\n",
      "INFO:tensorflow:global_step/sec: 265.257\n",
      "INFO:tensorflow:loss = 0.2932555, step = 1500 (0.377 sec)\n",
      "INFO:tensorflow:global_step/sec: 273.955\n",
      "INFO:tensorflow:loss = 0.3419354, step = 1600 (0.365 sec)\n",
      "INFO:tensorflow:global_step/sec: 270.262\n",
      "INFO:tensorflow:loss = 0.34852177, step = 1700 (0.370 sec)\n",
      "INFO:tensorflow:global_step/sec: 268.814\n",
      "INFO:tensorflow:loss = 0.4644045, step = 1800 (0.372 sec)\n",
      "INFO:tensorflow:global_step/sec: 260.434\n",
      "INFO:tensorflow:loss = 0.5414976, step = 1900 (0.384 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 1960 into linear_model\\model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 0.2623378.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow_estimator.python.estimator.canned.linear.LinearClassifierV2 at 0x14a077a3808>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "linear_output_dir = 'linear_model'\n",
    "if not os.path.exists(output_dir):\n",
    "    os.mkdir(output_dir)\n",
    "\n",
    "linear_estimator = tf.estimator.LinearClassifier(\n",
    "    model_dir = linear_output_dir,\n",
    "    n_classes = 2,\n",
    "    feature_columns = feature_columns)\n",
    "\n",
    "linear_estimator.train(input_fn = lambda : make_dataset(\n",
    "    train_df, y_train, epochs = 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n",
      "WARNING:tensorflow:Layer linear/linear_model is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2020-07-15T16:41:11Z\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from linear_model\\model.ckpt-1960\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Finished evaluation at 2020-07-15-16:41:13\n",
      "INFO:tensorflow:Saving dict for global step 1960: accuracy = 0.77272725, accuracy_baseline = 0.625, auc = 0.8345578, auc_precision_recall = 0.7801232, average_loss = 0.47881338, global_step = 1960, label/mean = 0.375, loss = 0.47469786, precision = 0.7294118, prediction/mean = 0.33076525, recall = 0.6262626\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 1960: linear_model\\model.ckpt-1960\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'accuracy': 0.77272725,\n",
       " 'accuracy_baseline': 0.625,\n",
       " 'auc': 0.8345578,\n",
       " 'auc_precision_recall': 0.7801232,\n",
       " 'average_loss': 0.47881338,\n",
       " 'label/mean': 0.375,\n",
       " 'loss': 0.47469786,\n",
       " 'precision': 0.7294118,\n",
       " 'prediction/mean': 0.33076525,\n",
       " 'recall': 0.6262626,\n",
       " 'global_step': 1960}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linear_estimator.evaluate(input_fn= lambda :make_dataset(eval_df,y_eval,epochs=1,shuffle=False,batch_size=20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using default config.\n",
      "INFO:tensorflow:Using config: {'_model_dir': 'dnn_model', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true\n",
      "graph_options {\n",
      "  rewrite_options {\n",
      "    meta_optimizer_iterations: ONE\n",
      "  }\n",
      "}\n",
      ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x0000014A079B29C8>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "WARNING:tensorflow:Layer dnn is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Saving checkpoints for 0 into dnn_model\\model.ckpt.\n",
      "INFO:tensorflow:loss = 2.0793557, step = 0\n",
      "INFO:tensorflow:global_step/sec: 181.974\n",
      "INFO:tensorflow:loss = 0.49542224, step = 100 (0.551 sec)\n",
      "INFO:tensorflow:global_step/sec: 234.269\n",
      "INFO:tensorflow:loss = 0.47333384, step = 200 (0.427 sec)\n",
      "INFO:tensorflow:global_step/sec: 222.817\n",
      "INFO:tensorflow:loss = 0.44431922, step = 300 (0.449 sec)\n",
      "INFO:tensorflow:global_step/sec: 236.479\n",
      "INFO:tensorflow:loss = 0.28831285, step = 400 (0.423 sec)\n",
      "INFO:tensorflow:global_step/sec: 235.37\n",
      "INFO:tensorflow:loss = 0.45867425, step = 500 (0.425 sec)\n",
      "INFO:tensorflow:global_step/sec: 233.179\n",
      "INFO:tensorflow:loss = 0.3657779, step = 600 (0.428 sec)\n",
      "INFO:tensorflow:global_step/sec: 236.48\n",
      "INFO:tensorflow:loss = 0.4788766, step = 700 (0.424 sec)\n",
      "INFO:tensorflow:global_step/sec: 233.179\n",
      "INFO:tensorflow:loss = 0.44059357, step = 800 (0.429 sec)\n",
      "INFO:tensorflow:global_step/sec: 234.27\n",
      "INFO:tensorflow:loss = 0.5106939, step = 900 (0.427 sec)\n",
      "INFO:tensorflow:global_step/sec: 222.322\n",
      "INFO:tensorflow:loss = 0.43084797, step = 1000 (0.449 sec)\n",
      "INFO:tensorflow:global_step/sec: 232.101\n",
      "INFO:tensorflow:loss = 0.48632675, step = 1100 (0.431 sec)\n",
      "INFO:tensorflow:global_step/sec: 235.369\n",
      "INFO:tensorflow:loss = 0.28230602, step = 1200 (0.425 sec)\n",
      "INFO:tensorflow:global_step/sec: 226.848\n",
      "INFO:tensorflow:loss = 0.33748236, step = 1300 (0.442 sec)\n",
      "INFO:tensorflow:global_step/sec: 232.639\n",
      "INFO:tensorflow:loss = 0.4059217, step = 1400 (0.429 sec)\n",
      "INFO:tensorflow:global_step/sec: 243.96\n",
      "INFO:tensorflow:loss = 0.5304049, step = 1500 (0.412 sec)\n",
      "INFO:tensorflow:global_step/sec: 251.296\n",
      "INFO:tensorflow:loss = 0.40382183, step = 1600 (0.398 sec)\n",
      "INFO:tensorflow:global_step/sec: 238.165\n",
      "INFO:tensorflow:loss = 0.09819677, step = 1700 (0.419 sec)\n",
      "INFO:tensorflow:global_step/sec: 239.874\n",
      "INFO:tensorflow:loss = 0.27827448, step = 1800 (0.417 sec)\n",
      "INFO:tensorflow:global_step/sec: 249.421\n",
      "INFO:tensorflow:loss = 0.314429, step = 1900 (0.400 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 1960 into dnn_model\\model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 0.25398466.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow_estimator.python.estimator.canned.dnn.DNNClassifierV2 at 0x14a13ce0288>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "dnn_output_dir = 'dnn_model'\n",
    "if not os.path.exists(output_dir):\n",
    "    os.mkdir(output_dir)\n",
    "\n",
    "dnn_estimator = tf.estimator.DNNClassifier(\n",
    "    model_dir = dnn_output_dir,\n",
    "    n_classes = 2,\n",
    "    feature_columns = feature_columns,\n",
    "    hidden_units=[128,128],\n",
    "    activation_fn=\"relu\",\n",
    "    optimizer=\"Adam\"\n",
    ")\n",
    "\n",
    "dnn_estimator.train(input_fn = lambda : make_dataset(\n",
    "    train_df, y_train, epochs = 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n",
      "WARNING:tensorflow:Layer dnn is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2020-07-15T16:44:30Z\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from dnn_model\\model.ckpt-1960\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Finished evaluation at 2020-07-15-16:44:31\n",
      "INFO:tensorflow:Saving dict for global step 1960: accuracy = 0.78409094, accuracy_baseline = 0.625, auc = 0.84582186, auc_precision_recall = 0.81326735, average_loss = 0.50721735, global_step = 1960, label/mean = 0.375, loss = 0.5091315, precision = 0.6779661, prediction/mean = 0.44203782, recall = 0.8080808\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 1960: dnn_model\\model.ckpt-1960\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'accuracy': 0.78409094,\n",
       " 'accuracy_baseline': 0.625,\n",
       " 'auc': 0.84582186,\n",
       " 'auc_precision_recall': 0.81326735,\n",
       " 'average_loss': 0.50721735,\n",
       " 'label/mean': 0.375,\n",
       " 'loss': 0.5091315,\n",
       " 'precision': 0.6779661,\n",
       " 'prediction/mean': 0.44203782,\n",
       " 'recall': 0.8080808,\n",
       " 'global_step': 1960}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dnn_estimator.evaluate(input_fn= lambda :make_dataset(eval_df,y_eval,epochs=1,shuffle=False,batch_size=20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:tf2]",
   "language": "python",
   "name": "conda-env-tf2-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
