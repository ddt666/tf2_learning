{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.13.1\n",
      "sys.version_info(major=3, minor=7, micro=7, releaselevel='final', serial=0)\n",
      "matplotlib 3.2.2\n",
      "numpy 1.18.5\n",
      "pandas 1.0.5\n",
      "sklearn 0.21.2\n",
      "tensorflow 1.13.1\n",
      "tensorflow._api.v1.keras 2.2.4-tf\n"
     ]
    }
   ],
   "source": [
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import sklearn\n",
    "import pandas as pd\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow import keras\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3' \n",
    "print(tf.__version__)\n",
    "print(sys.version_info)\n",
    "\n",
    "for module in mpl,np,pd,sklearn,tf,keras:\n",
    "    print(module.__name__,module.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>survived</th>\n",
       "      <th>sex</th>\n",
       "      <th>age</th>\n",
       "      <th>n_siblings_spouses</th>\n",
       "      <th>parch</th>\n",
       "      <th>fare</th>\n",
       "      <th>class</th>\n",
       "      <th>deck</th>\n",
       "      <th>embark_town</th>\n",
       "      <th>alone</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>Third</td>\n",
       "      <td>unknown</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>First</td>\n",
       "      <td>C</td>\n",
       "      <td>Cherbourg</td>\n",
       "      <td>n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>Third</td>\n",
       "      <td>unknown</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>First</td>\n",
       "      <td>C</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>male</td>\n",
       "      <td>28.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.4583</td>\n",
       "      <td>Third</td>\n",
       "      <td>unknown</td>\n",
       "      <td>Queenstown</td>\n",
       "      <td>y</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   survived     sex   age  n_siblings_spouses  parch     fare  class     deck  \\\n",
       "0         0    male  22.0                   1      0   7.2500  Third  unknown   \n",
       "1         1  female  38.0                   1      0  71.2833  First        C   \n",
       "2         1  female  26.0                   0      0   7.9250  Third  unknown   \n",
       "3         1  female  35.0                   1      0  53.1000  First        C   \n",
       "4         0    male  28.0                   0      0   8.4583  Third  unknown   \n",
       "\n",
       "   embark_town alone  \n",
       "0  Southampton     n  \n",
       "1    Cherbourg     n  \n",
       "2  Southampton     y  \n",
       "3  Southampton     n  \n",
       "4   Queenstown     y  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_file = \"../tf.Estimator/data/titanic/train.csv\"\n",
    "eval_file = \"../tf.Estimator/data/titanic/eval.csv\"\n",
    "\n",
    "train_df = pd.read_csv(train_file)\n",
    "eval_df = pd.read_csv(eval_file)\n",
    "\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = train_df.pop(\"survived\")\n",
    "y_eval = eval_df.pop(\"survived\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sex ['male' 'female']\n",
      "n_siblings_spouses [1 0 3 4 2 5 8]\n",
      "parch [0 1 2 5 3 4]\n",
      "class ['Third' 'First' 'Second']\n",
      "deck ['unknown' 'C' 'G' 'A' 'B' 'D' 'F' 'E']\n",
      "embark_town ['Southampton' 'Cherbourg' 'Queenstown' 'unknown']\n",
      "alone ['n' 'y']\n"
     ]
    }
   ],
   "source": [
    "categorical_columns = ['sex', 'n_siblings_spouses', 'parch', 'class',\n",
    "                       'deck', 'embark_town', 'alone']\n",
    "numeric_columns = ['age', 'fare']\n",
    "\n",
    "feature_columns = []\n",
    "for categorical_column in categorical_columns:\n",
    "    vocab = train_df[categorical_column].unique()\n",
    "    print(categorical_column, vocab)\n",
    "    feature_columns.append(\n",
    "        tf.feature_column.indicator_column(\n",
    "            tf.feature_column.categorical_column_with_vocabulary_list(\n",
    "                categorical_column, vocab)))\n",
    "\n",
    "for categorical_column in numeric_columns:\n",
    "    feature_columns.append(\n",
    "        tf.feature_column.numeric_column(\n",
    "            categorical_column, dtype=tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 离散型特征\n",
    "# categorical_columns = [\"sex\",\"n_siblings_spouses\",\"parch\",\"class\",\"deck\",\"embark_town\",\"alone\"]\n",
    "# # 连续型特征\n",
    "# numeric_columns = [\"age\",\"fare\"]\n",
    "\n",
    "# feature_columns = []\n",
    "\n",
    "# # 对离散型特征数据的处理\n",
    "# for categorical_column in categorical_columns:\n",
    "#     # 获得所有可能的值   \n",
    "#     vocab = train_df[categorical_column].unique()\n",
    "#     print(categorical_column,vocab)\n",
    "#     # indicator_column:对离散型数据进行onehot编码\n",
    "#     feature_columns.append(tf.feature_column.indicator_column(tf.feature_column.categorical_column_with_vocabulary_list(\n",
    "#         categorical_column,vocab\n",
    "#     )))\n",
    "    \n",
    "# # 对连续型特征数据进行处理\n",
    "# for categorical_column in numeric_columns:\n",
    "#     feature_columns.append(tf.feature_column.numeric_column(categorical_column,dtype=tf.float32))\n",
    "\n",
    "\n",
    "# print(feature_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_dataset(data_df, label_df, epochs = 10, shuffle = True,\n",
    "                 batch_size = 32):\n",
    "    dataset = tf.data.Dataset.from_tensor_slices(\n",
    "        (dict(data_df), label_df))\n",
    "    if shuffle:\n",
    "        dataset = dataset.shuffle(10000)\n",
    "    dataset = dataset.repeat(epochs).batch(batch_size)\n",
    "    return dataset.make_one_shot_iterator().get_next()\n",
    "\n",
    "# train_dataset = make_dataset(train_df,y_train,batch_size=5)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using default config.\n",
      "INFO:tensorflow:Using config: {'_model_dir': 'customized_estimator', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true\n",
      "graph_options {\n",
      "  rewrite_options {\n",
      "    meta_optimizer_iterations: ONE\n",
      "  }\n",
      "}\n",
      ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x0000023CAA08B6C8>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n",
      "WARNING:tensorflow:From F:\\Anaconda3\\envs\\tf1.13.1\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "WARNING:tensorflow:From F:\\Anaconda3\\envs\\tf1.13.1\\lib\\site-packages\\tensorflow\\python\\feature_column\\feature_column.py:205: NumericColumn._get_dense_tensor (from tensorflow.python.feature_column.feature_column_v2) is deprecated and will be removed after 2018-11-30.\n",
      "Instructions for updating:\n",
      "The old _FeatureColumn APIs are being deprecated. Please use the new FeatureColumn APIs instead.\n",
      "WARNING:tensorflow:From F:\\Anaconda3\\envs\\tf1.13.1\\lib\\site-packages\\tensorflow\\python\\feature_column\\feature_column.py:2121: NumericColumn._transform_feature (from tensorflow.python.feature_column.feature_column_v2) is deprecated and will be removed after 2018-11-30.\n",
      "Instructions for updating:\n",
      "The old _FeatureColumn APIs are being deprecated. Please use the new FeatureColumn APIs instead.\n",
      "WARNING:tensorflow:From F:\\Anaconda3\\envs\\tf1.13.1\\lib\\site-packages\\tensorflow\\python\\feature_column\\feature_column_v2.py:2703: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "WARNING:tensorflow:From F:\\Anaconda3\\envs\\tf1.13.1\\lib\\site-packages\\tensorflow\\python\\feature_column\\feature_column.py:206: NumericColumn._variable_shape (from tensorflow.python.feature_column.feature_column_v2) is deprecated and will be removed after 2018-11-30.\n",
      "Instructions for updating:\n",
      "The old _FeatureColumn APIs are being deprecated. Please use the new FeatureColumn APIs instead.\n",
      "WARNING:tensorflow:From F:\\Anaconda3\\envs\\tf1.13.1\\lib\\site-packages\\tensorflow\\python\\feature_column\\feature_column.py:205: IndicatorColumn._get_dense_tensor (from tensorflow.python.feature_column.feature_column_v2) is deprecated and will be removed after 2018-11-30.\n",
      "Instructions for updating:\n",
      "The old _FeatureColumn APIs are being deprecated. Please use the new FeatureColumn APIs instead.\n",
      "WARNING:tensorflow:From F:\\Anaconda3\\envs\\tf1.13.1\\lib\\site-packages\\tensorflow\\python\\feature_column\\feature_column.py:2121: IndicatorColumn._transform_feature (from tensorflow.python.feature_column.feature_column_v2) is deprecated and will be removed after 2018-11-30.\n",
      "Instructions for updating:\n",
      "The old _FeatureColumn APIs are being deprecated. Please use the new FeatureColumn APIs instead.\n",
      "WARNING:tensorflow:From F:\\Anaconda3\\envs\\tf1.13.1\\lib\\site-packages\\tensorflow\\python\\feature_column\\feature_column_v2.py:4295: VocabularyListCategoricalColumn._get_sparse_tensors (from tensorflow.python.feature_column.feature_column_v2) is deprecated and will be removed after 2018-11-30.\n",
      "Instructions for updating:\n",
      "The old _FeatureColumn APIs are being deprecated. Please use the new FeatureColumn APIs instead.\n",
      "WARNING:tensorflow:From F:\\Anaconda3\\envs\\tf1.13.1\\lib\\site-packages\\tensorflow\\python\\feature_column\\feature_column.py:2121: VocabularyListCategoricalColumn._transform_feature (from tensorflow.python.feature_column.feature_column_v2) is deprecated and will be removed after 2018-11-30.\n",
      "Instructions for updating:\n",
      "The old _FeatureColumn APIs are being deprecated. Please use the new FeatureColumn APIs instead.\n",
      "WARNING:tensorflow:From F:\\Anaconda3\\envs\\tf1.13.1\\lib\\site-packages\\tensorflow\\python\\ops\\lookup_ops.py:1137: to_int64 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "WARNING:tensorflow:From F:\\Anaconda3\\envs\\tf1.13.1\\lib\\site-packages\\tensorflow\\python\\feature_column\\feature_column_v2.py:4266: IndicatorColumn._variable_shape (from tensorflow.python.feature_column.feature_column_v2) is deprecated and will be removed after 2018-11-30.\n",
      "Instructions for updating:\n",
      "The old _FeatureColumn APIs are being deprecated. Please use the new FeatureColumn APIs instead.\n",
      "WARNING:tensorflow:From F:\\Anaconda3\\envs\\tf1.13.1\\lib\\site-packages\\tensorflow\\python\\feature_column\\feature_column_v2.py:4321: VocabularyListCategoricalColumn._num_buckets (from tensorflow.python.feature_column.feature_column_v2) is deprecated and will be removed after 2018-11-30.\n",
      "Instructions for updating:\n",
      "The old _FeatureColumn APIs are being deprecated. Please use the new FeatureColumn APIs instead.\n",
      "WARNING:tensorflow:From <ipython-input-10-bb2884ce01a8>:14: dense (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.dense instead.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Saving checkpoints for 0 into customized_estimator\\model.ckpt.\n",
      "INFO:tensorflow:loss = 1.0477638, step = 1\n",
      "INFO:tensorflow:global_step/sec: 539.069\n",
      "INFO:tensorflow:loss = 0.6929828, step = 101 (0.187 sec)\n",
      "INFO:tensorflow:global_step/sec: 903.302\n",
      "INFO:tensorflow:loss = 0.4990836, step = 201 (0.110 sec)\n",
      "INFO:tensorflow:global_step/sec: 887.336\n",
      "INFO:tensorflow:loss = 0.37137777, step = 301 (0.113 sec)\n",
      "INFO:tensorflow:global_step/sec: 945.905\n",
      "INFO:tensorflow:loss = 0.4096049, step = 401 (0.106 sec)\n",
      "INFO:tensorflow:global_step/sec: 919.87\n",
      "INFO:tensorflow:loss = 0.51612777, step = 501 (0.109 sec)\n",
      "INFO:tensorflow:global_step/sec: 954.957\n",
      "INFO:tensorflow:loss = 0.5591787, step = 601 (0.105 sec)\n",
      "INFO:tensorflow:global_step/sec: 945.911\n",
      "INFO:tensorflow:loss = 0.4169856, step = 701 (0.107 sec)\n",
      "INFO:tensorflow:global_step/sec: 895.245\n",
      "INFO:tensorflow:loss = 0.545049, step = 801 (0.111 sec)\n",
      "INFO:tensorflow:global_step/sec: 871.841\n",
      "INFO:tensorflow:loss = 0.37878102, step = 901 (0.117 sec)\n",
      "INFO:tensorflow:global_step/sec: 964.17\n",
      "INFO:tensorflow:loss = 0.5704278, step = 1001 (0.102 sec)\n",
      "INFO:tensorflow:global_step/sec: 1066.67\n",
      "INFO:tensorflow:loss = 0.40515035, step = 1101 (0.094 sec)\n",
      "INFO:tensorflow:global_step/sec: 945.926\n",
      "INFO:tensorflow:loss = 0.362005, step = 1201 (0.106 sec)\n",
      "INFO:tensorflow:global_step/sec: 1044.44\n",
      "INFO:tensorflow:loss = 0.3783006, step = 1301 (0.097 sec)\n",
      "INFO:tensorflow:global_step/sec: 1023.15\n",
      "INFO:tensorflow:loss = 0.31857258, step = 1401 (0.098 sec)\n",
      "INFO:tensorflow:global_step/sec: 1023.13\n",
      "INFO:tensorflow:loss = 0.43560994, step = 1501 (0.097 sec)\n",
      "INFO:tensorflow:global_step/sec: 1044.46\n",
      "INFO:tensorflow:loss = 0.48977986, step = 1601 (0.096 sec)\n",
      "INFO:tensorflow:global_step/sec: 1033.68\n",
      "INFO:tensorflow:loss = 0.33078584, step = 1701 (0.097 sec)\n",
      "INFO:tensorflow:global_step/sec: 1193.66\n",
      "INFO:tensorflow:loss = 0.4311052, step = 1801 (0.085 sec)\n",
      "INFO:tensorflow:global_step/sec: 1089.86\n",
      "INFO:tensorflow:loss = 0.23252523, step = 1901 (0.091 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 1960 into customized_estimator\\model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 0.40092894.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow_estimator.python.estimator.estimator.Estimator at 0x23ca7cd0348>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 自定义estimator\n",
    "\n",
    "output_dir = \"customized_estimator\"\n",
    "if not os.path.exists(output_dir):\n",
    "    os.mkdir(output_dir)\n",
    "\n",
    "def model_fn(features, labels, mode, params):\n",
    "    # model runtime state: Train, Eval, Predict\n",
    "    input_for_next_layer = tf.feature_column.input_layer(\n",
    "        features, params['feature_columns'])\n",
    "    for n_unit in params['hidden_units']:\n",
    "        input_for_next_layer = tf.layers.dense(input_for_next_layer,\n",
    "                                               units = n_unit,\n",
    "                                               activation = tf.nn.relu)\n",
    "    logits = tf.layers.dense(input_for_next_layer,\n",
    "                             params['n_classes'],\n",
    "                             activation = None)\n",
    "    predicted_classes = tf.argmax(logits, 1)\n",
    "    \n",
    "    if mode == tf.estimator.ModeKeys.PREDICT:\n",
    "        predictions = {\n",
    "            \"class_ids\": predicted_classes[:, tf.newaxis],\n",
    "            \"probabilities\": tf.nn.softmax(logits),\n",
    "            \"logits\": logits\n",
    "        }\n",
    "        return tf.estimator.EstimatorSpec(mode,\n",
    "                                          predictions = predictions)\n",
    "    \n",
    "    loss = tf.losses.sparse_softmax_cross_entropy(labels = labels,\n",
    "                                                  logits = logits)\n",
    "    accuracy = tf.metrics.accuracy(labels = labels,\n",
    "                                   predictions = predicted_classes,\n",
    "                                   name = \"acc_op\")\n",
    "    metrics = {\"accuracy\": accuracy}\n",
    "    if mode == tf.estimator.ModeKeys.EVAL:\n",
    "        return tf.estimator.EstimatorSpec(mode, loss = loss,\n",
    "                                          eval_metric_ops = metrics)\n",
    "    optimizer = tf.train.AdamOptimizer()\n",
    "    train_op = optimizer.minimize(\n",
    "        loss, global_step = tf.train.get_global_step())\n",
    "    return tf.estimator.EstimatorSpec(mode, loss = loss,\n",
    "                                      train_op = train_op)\n",
    "\n",
    "estimator = tf.estimator.Estimator(\n",
    "    model_fn = model_fn,\n",
    "    model_dir = output_dir,\n",
    "    params = {\n",
    "        \"feature_columns\": feature_columns,\n",
    "        \"hidden_units\": [100, 100],\n",
    "        \"n_classes\": 2\n",
    "    })\n",
    "estimator.train(input_fn = lambda : make_dataset(\n",
    "    train_df, y_train, epochs = 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2020-07-17T08:54:00Z\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "WARNING:tensorflow:From F:\\Anaconda3\\envs\\tf1.13.1\\lib\\site-packages\\tensorflow\\python\\training\\saver.py:1266: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use standard file APIs to check for files with this prefix.\n",
      "INFO:tensorflow:Restoring parameters from customized_estimator\\model.ckpt-1960\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Finished evaluation at 2020-07-17-08:54:00\n",
      "INFO:tensorflow:Saving dict for global step 1960: accuracy = 0.7916667, global_step = 1960, loss = 0.4927668\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 1960: customized_estimator\\model.ckpt-1960\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'accuracy': 0.7916667, 'loss': 0.4927668, 'global_step': 1960}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "estimator.evaluate(lambda : make_dataset(\n",
    "    eval_df, y_eval, epochs = 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:tf1.13.1]",
   "language": "python",
   "name": "conda-env-tf1.13.1-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
